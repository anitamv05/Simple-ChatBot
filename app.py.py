# -*- coding: utf-8 -*-
"""Simple Chatbot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1owYnOd4I8ZvWLRni-EitT72WH3jy33zK
"""





import streamlit as st
from langchain.prompts import PromptTemplate
from langchain.memory import ConversationBufferMemory
from langchain import ConversationChain
from langchain.chat_models import ChatOpenAI

from google.colab import userdata
userdata.get('OPENAI_API_KEY')

import os
os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')

# Define the conversation template and memory
prompt_template = PromptTemplate(
    input_variables=["history", "input"],
    template="""
    The following is a conversation between a user and an AI assistant. The assistant is helpful, creative, clever, and very friendly.

    {history}

    User: {input}
    Assistant:"""
)

memory = ConversationBufferMemory()
llm = ChatOpenAI(model="gpt-4", temperature=0.6)
conversation = ConversationChain(llm=llm, prompt=prompt_template, memory=memory)

# Streamlit app layout
st.title("Chatbot Demo")
st.write("Ask anything and get a response from the AI!")

# User input
user_input = st.text_input("You: ", "Hello, who are you?")

if user_input:
    response = conversation.predict(input=user_input)
    st.write(f"AI: {response}")
